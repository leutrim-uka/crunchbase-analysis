{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERTopic + Llama for Topic Modeling on Cruncbase company descriptions\n",
    "A straight-forward implementation of the Topic Modelling code in the repo\n",
    "## Install dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir scikit-learn==1.5.0\n",
    "!pip install --no-cache-dir cudf-cu12==24.6.0 dask-cudf-cu12==24.6.0 --extra-index-url=https://pypi.nvidia.com\n",
    "!pip install --no-cache-dir cuml-cu12==24.6.0 --extra-index-url=https://pypi.nvidia.com\n",
    "!pip install --no-cache-dir cugraph-cu12==24.6.0 --extra-index-url=https://pypi.nvidia.com\n",
    "!pip install --no-cache-dir cupy-cuda12x==13.1.0 -f https://pip.cupy.dev/aarch64\n",
    "\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\n",
    "!pip install bertopic\n",
    "\n",
    "!git clone https://github.com/TutteInstitute/datamapplot.git\n",
    "!pip install datamapplot/.\n",
    "\n",
    "!wget https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Use llama.cpp to load in a Quantized LLM\n",
    "llm = Llama(model_path=\"openhermes-2.5-mistral-7b.Q4_K_M.gguf\", n_gpu_layers=-1, n_ctx=4096, stop=[\"Q:\", \"\\n\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, LlamaCPP\n",
    "\n",
    "prompt = \"\"\" Q:\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the above information, can you generate one to three classes of typical events in the given setting?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "representation_model = {\n",
    "    \"KeyBERT\": KeyBERTInspired(),\n",
    "    \"LLM\": LlamaCPP(llm, prompt=prompt),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_dir = \"/content/drive/MyDrive/Potsdam/ClassMining\"\n",
    "data = \"/data\"\n",
    "models = \"/models\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "organizations_filepath = f\"{base_dir}{data}/organization_descriptions.csv\"\n",
    "descriptions = pd.read_csv(organizations_filepath, usecols=['description'])['description'].to_list()\n",
    "\n",
    "print(f\"Descriptions before cleaning: {len(descriptions)}\")\n",
    "\n",
    "# Remove empty strings and null elements\n",
    "documents = [text for text in descriptions if text != '' and pd.notna(text)]\n",
    "\n",
    "# Make sure each element is a string\n",
    "documents = [str(text) for text in documents]\n",
    "\n",
    "print(f\"Descriptions after cleaning: {len(descriptions)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings = embedding_model.encode(documents, show_progress_bar=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_components=5, n_neighbors=20, random_state=42, metric=\"cosine\", verbose=True)\n",
    "hdbscan_model = HDBSCAN(min_samples=30, prediction_data=True, cluster_selection_method='eom', min_cluster_size=400, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Sub-models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics, probs = topic_model.fit_transform(documents, embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show topics\n",
    "topic_model.get_topic_info()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
